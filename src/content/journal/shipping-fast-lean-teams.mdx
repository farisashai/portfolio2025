---
title: "Shipping Fast on Lean Teams"
description: "Lessons in maintaining craft and velocity without burning out or breaking trust"
year: "November 2025"
keywords: "Frontend, Engineering, Velocity, Quality, AI Tools, Systems"
labels: ["Engineering"]
featured: false
draft: true
---

When I joined Formal as the only frontend engineer, I inherited every pixel the company shipped. Every backend change needed UI surfaces. Every permission model update needed new affordances. Every customer complaint about spacing, responsiveness, or broken focus states landed directly on my desk. The backend team—six engineers writing Go—moved quickly. My job was to ensure the frontend never became the bottleneck.

AI made me faster, but it didn’t spare me from judgment. In the early months, I generated code so quickly that I stopped taking the time to understand it. Each iteration layered more complexity into the logic. I duplicated fixes I’d already made elsewhere. I missed edge cases because I was prompting AI without fully grasping what I was asking for.

These weren’t classic “bugs.” They were failures of engineering judgment. Modern tools don’t eliminate the need for judgment—they amplify the cost of lacking it. AI accelerates your thinking, whether your thinking is solid or shallow.

This article is the mindset I’ve developed at the intersection of frontend craft, system design, product sensitivity, and the pressure of being solely responsible for user trust in a fast-moving environment.

---

# Principle 1: Stability Enables Speed

Last year, Bun was everywhere—benchmarks, hype, excitement about faster installs and better DX. As someone who likes to push engineering forward, I fell into the common trap: I tried optimizing systems that weren’t asking to be optimized. I spun up a Next.js + Bun project and immediately ran into issues. Packages that worked flawlessly in Node broke in subtle ways. Integrations failed. Pages crashed.

The lesson wasn’t that Bun was flawed—it’s now far more mature. The lesson was that **timing matters more than technology**. When you adopt tools early, you become the one discovering the landmines. You pay the ecosystem’s learning cost.

If your job is to ship consistently with high reliability, the boring stack—the stable, well-worn, community-validated stack—will almost always outperform the clever one. Stability is a force multiplier: fewer surprises, better documentation, broader community testing, and critically, AI models with stronger priors and lower error rates.

AI thrives on mature ecosystems. If I ask it to refactor a Next.js component, it knows the patterns. If I ask it to navigate an experimental runtime, I end up teaching the model while I’m learning myself. That’s a slowdown disguised as innovation.

Exploration is valuable. But shipping at velocity requires foundations that don’t wobble.

Stability isn’t conservatism.
**Stability is what lets you move fast without tripping.**

---

# Principle 2: Minimize Surface Area for Failure

Every decision, dependency, pattern, or abstraction creates surface area for failure. Reducing unnecessary surface area is one of the highest-leverage skills you can develop on a small team.

I approach engineering like minimalism: start with the simplest thing that works, and only add complexity when its absence becomes a real bottleneck. Many teams do the opposite—they build infrastructure “just in case,” masking speculation as responsibility. This creates premature complexity without real value.

When I joined Formal, I could have built:

* a feature-flag framework
* a large component library
* a caching layer
* a full internal design system
* custom observability

All of these are genuinely valuable—*when the team and product are ready*. But early on, none were blocking us. So I didn’t build them. We shipped features. Only when something actually hurt did we add the least-complex system required to relieve the constraint. Not the future-proof version. Not the generalized version. Just enough to remove the current friction.

The nuance:
**Large organizations absolutely do have long-timescale problems.**
These aren’t speculative—they’re real sources of future pain that compound slowly. Logging strategy, domain modeling, operational risk, security boundaries—ignoring these eventually becomes catastrophic. But those are genuine constraints, not imagined ones.

The art is recognizing the difference.

Real constraints block progress.
Imagined constraints make you feel smart.
Solving only real constraints keeps you fast.

---

# Principle 3: Understand the True Cost of Context Switching

AI’s speed creates a cognitive trap: because the system makes progress while you’re distracted, you feel capable of juggling more complexity than you can handle. But your attention does not scale. Context switching is expensive—especially when the work is ambiguous, taste-driven, or architectural.

Worse, some tasks will never be “one-shot” no matter how well-crafted the prompt:

* the right solution isn’t known upfront
* the tradeoffs are subjective
* constraints are uncertain
* the best direction emerges only through iteration
* a long “perfect prompt” is brittle or wrong

For these tasks—design, UX flows, complex interactions, architectural boundaries—AI is best as a stepwise collaborator: take a step, observe, critique, refine. Discovery can’t be automated.

But in any organization with real velocity, you will get interrupted constantly:
new enum cases, schema shifts, permission updates, config rewrites. These require almost no deep thought. They’re chores. I routinely automate them via Cursor—even directly from Slack—and let the agent output a clean PR that I review later with full attention.

My workflow is built around this distinction:

* Keep multiple Git worktrees open.
* Focus all attention on a single ambiguous task.
* Let AI handle mechanical tasks in the background.
* Review those PRs intentionally, not reactively.

AI increases throughput.
Your mind remains the bottleneck.
Flow state must be protected, not oversubscribed.

---

# Principle 4: Build Systems Only Where Invariants Are Stable

Not everything needs a system. Systems should only be built where the rules will outlive the business logic.

Examples:

* lint rules encoding style and architectural boundaries
* GritQL patterns enforcing consistent component structure
* static type guarantees from domain models
* automated checks for known pitfalls and regressions

These systems reduce cognitive load because their invariants rarely change. They require minimal upkeep. If the underlying language or framework changes dramatically, the system simply stops applying—it doesn’t create drag.

The right systems free you.
The wrong systems burden you.

My heuristic:

* If something appears twice, encode the rule.
* If a mistake appears twice, block it.
* If a system prevents entire categories of thinking, it’s worth building.

This is how you build a self-reinforcing engineering environment—one where the effort you invest once continues paying dividends indefinitely.

Here’s my personal north star:
**If I disappeared for a week, could someone ship code that looks exactly like mine?**
Not philosophically similar.
Not “basically the same.”
**Indistinguishable.**

That’s when you know the systems are doing the work.
Not heroics. Not taste. Not vigilance. Systems.

---

# Principle 5: A Working Solution Is Not the Correct Solution

AI is excellent at producing working implementations. But “works” and “correct” are different layers.

Correctness includes:

* meaningful boundaries
* stable invariants
* alignment with domain concepts
* extensibility under evolving requirements
* clarity for future readers
* predictable performance characteristics

AI doesn’t know the unwritten rules:
how your team names things, how components should feel, what constitutes good UI, what abstractions are sacred. Unless you over-specify—which is slow and brittle—the model fills gaps with plausible guesses.

That’s why I review AI output with more scrutiny than human output. Not because AI is careless, but because it lacks context.

My review questions:

* Would I structure it this way by hand?
* Will this scale when requirements change?
* Are the abstractions overly clever?
* Does it duplicate existing patterns?
* Is cognitive load proportional to what it does?

AI accelerates execution.
It also accelerates the consequences of poor judgment.

Your job isn’t to merge code faster.
Your job is to ensure correctness scales with velocity.

---

# Principle 6: Determinism Beats Intelligence Where It Matters

AI is too slow and inconsistent to enforce mechanical rules. A PR agent might take 45 seconds. A static linter runs in milliseconds. Deterministic enforcement belongs to deterministic tools.

AI’s real power is in generating those deterministic tools.

My feedback loop now looks like:

1. Notice a pattern violation.
2. Spend ~10 minutes with AI writing a lint rule or GritQL pattern.
3. Commit it once.
4. Never think about it again.

Mechanical correctness becomes instant.
Semantic correctness becomes AI-assisted.

This separation allows speed *and* safety.

Static:

* TypeScript
* Biome
* ESLint
* GritQL
  Provide structural guarantees.

AI:

* readability
* architectural coherence
* naming
* UX flow coherence
  Provide qualitative insight that resists formalization.

Use each tool where it excels.

---

# Principle 7: The Frontend Is the Trust Boundary

Frontend engineers don’t control data correctness—but we absolutely control how reliable the product *feels*. A backend failure can be invisible if the UI gracefully recovers: retry flows, clear messaging, safe fallbacks. But a small UI failure—missing focus state, broken layout, unresponsive button—shatters trust immediately.

Users judge reliability by what they touch.

This shapes how I approach quality. I maintain a mental checklist for every user-facing change:

* functional correctness
* accessibility
* responsiveness
* error states and fallback UI
* code clarity and duplication
* performance and bundle cost
* alignment with our design system

Not every dimension matters for every PR, but knowing the space means I can spot trust boundaries quickly.

Imperfection is inevitable, but risks are not equal:

* Critical-path functional bugs: zero tolerance.
* Visual glitches: batch and refine later.
* Systems changes: high caution, manual validation.
* Nice-to-haves: ship when ready.

The skill is knowing when to slow down. You slow down at trust boundaries—data paths, accessibility changes, dependency updates—because the cost of mistakes is high and automation cannot replace judgment.

---

# Principle 8: Speed Is a Property of Systems, Not Effort

I’ve rewritten entire features from scratch because the first version’s boundaries were wrong. When boundaries are wrong, bugs multiply. When boundaries are right, bugs vanish.

It’s cheaper to evaluate a bad plan than to understand bad code. Before delegating anything to AI, I ask for the plan. If I can’t understand the plan, I slow down and treat the implementation with suspicion.

Velocity is not “typing faster.”
Velocity is reducing cognitive load and increasing clarity so decisions take less energy and systems take more responsibility.

This reframes the job:

The output of a senior engineer isn’t code.
The output is **product decisions made with clarity and confidence**.

AI increases throughput, but it cannot increase your judgment. You can’t scale velocity faster than you can scale understanding.

The long-term compounding value comes from systems:

* each bug caught becomes a permanent rule
* each architectural decision becomes a shared pattern
* each repeated mistake becomes a blocked path
* each successful abstraction reduces future friction

Over time, the codebase becomes self-defending—and velocity becomes independent of who’s typing.

---

# Conclusion

Quality isn’t achieved through vigilance.
Quality emerges from systems that make the right thing easy and the wrong thing hard.

When your tools, patterns, automation, and judgment align, speed stops being a trade-off with safety. They become the same thing. That’s how one frontend engineer keeps pace with six backend engineers, protects trust, and ships at the speed modern teams demand.
